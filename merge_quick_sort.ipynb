{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: memory_profiler in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (0.61.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from memory_profiler) (5.9.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from memory_profiler import memory_usage\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data import\n",
    "https://www.kaggle.com/datasets/maharshipandya/-spotify-tracks-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('music_data.csv')\n",
    "\n",
    "# Select only the relevant columns\n",
    "filtered_df = df[['track_id', 'artists', 'album_name', 'track_name', 'popularity', 'track_genre']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle dataset function\n",
    "def shuffle_dataset(data):\n",
    "    data = data.sample(frac=1, random_state=random.randint(1, 2000)).reset_index(drop=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Sort implementation for `track_genre` and `popularity`\n",
    "def merge_sort(data, key1, key2):\n",
    "    \"\"\"\n",
    "    Merge Sort implementation for sorting by two keys:\n",
    "    - Primary Key: `key1` ('track_genre') in ascending order.\n",
    "    - Secondary Key: `key2` ('popularity') in descending order within key1 groups.\n",
    "    \n",
    "    Args:\n",
    "        data (list): List of dictionaries to be sorted.\n",
    "        key1 (str): Primary sorting key ('track_genre').\n",
    "        key2 (str): Secondary sorting key ('popularity').\n",
    "\n",
    "    Returns:\n",
    "        list: Sorted list of dictionaries.\n",
    "    \"\"\"\n",
    "    if len(data) <= 1:\n",
    "        return data\n",
    "\n",
    "    mid = len(data) // 2\n",
    "    left = merge_sort(data[:mid], key1, key2)\n",
    "    right = merge_sort(data[mid:], key1, key2)\n",
    "\n",
    "    return merge_genre_popularity(left, right, key1, key2)\n",
    "\n",
    "def merge_genre_popularity(left, right, key1, key2):\n",
    "    \"\"\"\n",
    "    Merge function for sorting by two keys.\n",
    "\n",
    "    Args:\n",
    "        left (list): Left half of the data.\n",
    "        right (list): Right half of the data.\n",
    "\n",
    "    Returns:\n",
    "        list: Merged and sorted list.\n",
    "    \"\"\"\n",
    "    sorted_data = []\n",
    "    i = j = 0\n",
    "\n",
    "    while i < len(left) and j < len(right):\n",
    "        # Compare by primary key (track_genre)\n",
    "        if left[i][key1] < right[j][key1]:\n",
    "            sorted_data.append(left[i])\n",
    "            i += 1\n",
    "        elif left[i][key1] > right[j][key1]:\n",
    "            sorted_data.append(right[j])\n",
    "            j += 1\n",
    "        else:\n",
    "            # If primary key is equal, compare by secondary key (popularity, descending)\n",
    "            if left[i][key2] >= right[j][key2]:\n",
    "                sorted_data.append(left[i])\n",
    "                i += 1\n",
    "            else:\n",
    "                sorted_data.append(right[j])\n",
    "                j += 1\n",
    "\n",
    "    # Append remaining elements\n",
    "    sorted_data.extend(left[i:])\n",
    "    sorted_data.extend(right[j:])\n",
    "\n",
    "    return sorted_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_sort(data, key1, key2, low=0, high=None):\n",
    "    \"\"\"\n",
    "    Optimized Quick Sort with in-place partitioning and median-of-three pivot selection.\n",
    "    Sorts data by key1 (genre) in ascending order and key2 (popularity) in descending order within key1 groups.\n",
    "\n",
    "    Arguments explantion:\n",
    "        data (list): List of dictionaries to be sorted.\n",
    "        key1 (str): First key for sorting ('track_genre')\n",
    "        key2 (str): Second key for sorting ('popularity')\n",
    "        low (int): Starting index for the partition\n",
    "        high (int): Ending index for the partition\n",
    "\n",
    "    Returns:\n",
    "        None: The list is sorted in place.\n",
    "    \"\"\"\n",
    "    if high is None:\n",
    "        high = len(data) - 1\n",
    "\n",
    "    if low < high:\n",
    "        # Get the partition index\n",
    "        pivot_index = partition(data, key1, key2, low, high)\n",
    "\n",
    "        # Recursively sort left and right partitions\n",
    "        quick_sort(data, key1, key2, low, pivot_index - 1)\n",
    "        quick_sort(data, key1, key2, pivot_index + 1, high)\n",
    "\n",
    "\n",
    "def median_of_three(data, key1, key2, low, high):\n",
    "    \"\"\"\n",
    "    Select the median-of-three pivot for better partitioning.\n",
    "    Returns: int: Index of the median element.\n",
    "    \"\"\"\n",
    "    mid = (low + high) // 2\n",
    "\n",
    "    # Sort the low, mid, and high indices based on key1 and key2\n",
    "    candidates = [low, mid, high]\n",
    "    candidates.sort(key=lambda x: (data[x][key1], -data[x][key2]))  # Sort by key1, then key2 descending\n",
    "\n",
    "    # Return the index of the median\n",
    "    return candidates[1]\n",
    "\n",
    "\n",
    "def partition(data, key1, key2, low, high):\n",
    "    pivot_index = median_of_three(data, key1, key2, low, high)\n",
    "    data[pivot_index], data[high] = data[high], data[pivot_index]\n",
    "    pivot = data[high]\n",
    "    i = low - 1\n",
    "    for j in range(low, high):\n",
    "        if data[j][key1] < pivot[key1] or (data[j][key1] == pivot[key1] and data[j][key2] >= pivot[key2]):\n",
    "            i += 1\n",
    "            data[i], data[j] = data[j], data[i]\n",
    "    data[i + 1], data[high] = data[high], data[i + 1]\n",
    "    return i + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark for quick sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Benchmarking Quick Sort:\n",
      "Quick Sort 1 attempt Execution Time: 2.483814 seconds\n",
      "Quick Sort 1 attempt Peak Memory Usage: 0.95 MB\n",
      "Quick Sort 2 attempt Execution Time: 2.403848 seconds\n",
      "Quick Sort 2 attempt Peak Memory Usage: 0.14 MB\n",
      "Quick Sort 3 attempt Execution Time: 2.424670 seconds\n",
      "Quick Sort 3 attempt Peak Memory Usage: 0.16 MB\n",
      "Quick Sort 4 attempt Execution Time: 2.457765 seconds\n",
      "Quick Sort 4 attempt Peak Memory Usage: 0.07 MB\n",
      "Quick Sort 5 attempt Execution Time: 2.440058 seconds\n",
      "Quick Sort 5 attempt Peak Memory Usage: 0.14 MB\n",
      "Quick Sort Average Execution Time: 2.442031 seconds\n",
      "Quick Sort Average Peak Memory Usage: 0.29 MB\n",
      "\n",
      "Sorted Dataset (Quick Sort):\n",
      "                 track_id                    artists  \\\n",
      "0  5vjLSffimiIP26QG5WcN2K           Chord Overstreet   \n",
      "1  1EzrEOXmMH3G43AXT1y7pA                 Jason Mraz   \n",
      "2  3S0OXQeoh0w6AY8WQVckRW                 Jason Mraz   \n",
      "3  08MFgEQeVLF37EyZ7jcwLc               Zack Tabudlo   \n",
      "4  0IktbUcnAGrvD03AWnz3Q8  Jason Mraz;Colbie Caillat   \n",
      "\n",
      "                            album_name track_name  popularity track_genre  \n",
      "0                              Hold On    Hold On          82    acoustic  \n",
      "1  We Sing. We Dance. We Steal Things.  I'm Yours          80    acoustic  \n",
      "2  We Sing. We Dance. We Steal Things.  I'm Yours          75    acoustic  \n",
      "3                                 Pano       Pano          75    acoustic  \n",
      "4  We Sing. We Dance. We Steal Things.      Lucky          74    acoustic  \n"
     ]
    }
   ],
   "source": [
    "# Benchmarking function for Quick Sort\n",
    "def benchmark_quick_sort(sort_function, sort_name):\n",
    "    total_time = 0\n",
    "    total_memory = 0\n",
    "    runs = 5  # Number of runs\n",
    "    sorted_data = None\n",
    "\n",
    "    for _ in range(runs):\n",
    "        # Shuffle the dataset\n",
    "        shuffled_dataset = shuffle_dataset(filtered_df)\n",
    "        data_list = shuffled_dataset.to_dict('records')\n",
    "\n",
    "        # Measure memory usage and execution time\n",
    "        mem_usage = memory_usage((sort_function, (data_list, 'track_genre', 'popularity')))\n",
    "        start_time = time.time()\n",
    "        sort_function(data_list, 'track_genre', 'popularity')\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Calculate time and memory used\n",
    "        time_used = end_time - start_time\n",
    "        memory_used = max(mem_usage) - min(mem_usage)\n",
    "\n",
    "        # Add to totals\n",
    "        total_time += time_used\n",
    "        total_memory += memory_used\n",
    "\n",
    "        print(f\"{sort_name} {_+1} attempt Execution Time: {time_used:.6f} seconds\")\n",
    "        print(f\"{sort_name} {_+1} attempt Peak Memory Usage: {memory_used:.2f} MB\")\n",
    "\n",
    "        # Save the sorted data from the last run\n",
    "        if _ == runs - 1:\n",
    "            sorted_data = data_list\n",
    "\n",
    "    # Calculate averages\n",
    "    avg_time = total_time / runs\n",
    "    avg_memory = total_memory / runs\n",
    "\n",
    "    print(f\"{sort_name} Average Execution Time: {avg_time:.6f} seconds\")\n",
    "    print(f\"{sort_name} Average Peak Memory Usage: {avg_memory:.2f} MB\")\n",
    "\n",
    "    return sorted_data\n",
    "\n",
    "# Run Quick Sort and benchmark it\n",
    "print(\"\\nBenchmarking Quick Sort:\")\n",
    "sorted_data_quick = benchmark_quick_sort(quick_sort, \"Quick Sort\")\n",
    "\n",
    "# Display the sorted dataset\n",
    "print(\"\\nSorted Dataset (Quick Sort):\")\n",
    "sorted_df_quick = pd.DataFrame(sorted_data_quick)\n",
    "print(sorted_df_quick.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark for merge sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Benchmarking Merge Sort:\n",
      "Merge Sort 1 attempt Execution Time: 0.944921 seconds\n",
      "Merge Sort 1 attempt Peak Memory Usage: 3.04 MB\n",
      "Merge Sort 2 attempt Execution Time: 0.981021 seconds\n",
      "Merge Sort 2 attempt Peak Memory Usage: 4.48 MB\n",
      "Merge Sort 3 attempt Execution Time: 0.969810 seconds\n",
      "Merge Sort 3 attempt Peak Memory Usage: 2.23 MB\n",
      "Merge Sort 4 attempt Execution Time: 0.963612 seconds\n",
      "Merge Sort 4 attempt Peak Memory Usage: 1.90 MB\n",
      "Merge Sort 5 attempt Execution Time: 0.917795 seconds\n",
      "Merge Sort 5 attempt Peak Memory Usage: 1.72 MB\n",
      "Merge Sort Average Execution Time: 0.955432 seconds\n",
      "Merge Sort Average Peak Memory Usage: 2.67 MB\n",
      "\n",
      "Sorted Dataset (Merge Sort):\n",
      "                 track_id                    artists  \\\n",
      "0  5vjLSffimiIP26QG5WcN2K           Chord Overstreet   \n",
      "1  1EzrEOXmMH3G43AXT1y7pA                 Jason Mraz   \n",
      "2  3S0OXQeoh0w6AY8WQVckRW                 Jason Mraz   \n",
      "3  08MFgEQeVLF37EyZ7jcwLc               Zack Tabudlo   \n",
      "4  0IktbUcnAGrvD03AWnz3Q8  Jason Mraz;Colbie Caillat   \n",
      "\n",
      "                            album_name track_name  popularity track_genre  \n",
      "0                              Hold On    Hold On          82    acoustic  \n",
      "1  We Sing. We Dance. We Steal Things.  I'm Yours          80    acoustic  \n",
      "2  We Sing. We Dance. We Steal Things.  I'm Yours          75    acoustic  \n",
      "3                                 Pano       Pano          75    acoustic  \n",
      "4  We Sing. We Dance. We Steal Things.      Lucky          74    acoustic  \n"
     ]
    }
   ],
   "source": [
    "# Benchmarking function for Merge Sort\n",
    "def benchmark_merge_sort(sort_function, sort_name):\n",
    "    total_time = 0\n",
    "    total_memory = 0\n",
    "    runs = 5  # Number of runs\n",
    "    sorted_data = None\n",
    "\n",
    "    for _ in range(runs):\n",
    "        # Shuffle the dataset\n",
    "        shuffled_dataset = shuffle_dataset(filtered_df)\n",
    "        data_list = shuffled_dataset.to_dict('records')\n",
    "\n",
    "        # Measure memory usage and execution time\n",
    "        mem_usage = memory_usage((sort_function, (data_list, 'track_genre', 'popularity')))\n",
    "        start_time = time.time()\n",
    "        sorted_data = sort_function(data_list, 'track_genre', 'popularity')\n",
    "        end_time = time.time()\n",
    "        # Calculate time and memory used\n",
    "        time_used = end_time - start_time\n",
    "        memory_used = max(mem_usage) - min(mem_usage)\n",
    "\n",
    "        # Add to totals\n",
    "        total_time += time_used\n",
    "        total_memory += memory_used\n",
    "\n",
    "        print(f\"{sort_name} {_+1} attempt Execution Time: {time_used:.6f} seconds\")\n",
    "        print(f\"{sort_name} {_+1} attempt Peak Memory Usage: {memory_used:.2f} MB\")\n",
    "\n",
    "        # \n",
    "    # Calculate averages\n",
    "    avg_time = total_time / runs\n",
    "    avg_memory = total_memory / runs\n",
    "\n",
    "    print(f\"{sort_name} Average Execution Time: {avg_time:.6f} seconds\")\n",
    "    print(f\"{sort_name} Average Peak Memory Usage: {avg_memory:.2f} MB\")\n",
    "\n",
    "    return sorted_data\n",
    "\n",
    "# Run Merge Sort and benchmark it\n",
    "print(\"\\nBenchmarking Merge Sort:\")\n",
    "sorted_data_merge = benchmark_merge_sort(merge_sort, \"Merge Sort\")\n",
    "\n",
    "# Display the sorted dataset\n",
    "print(\"\\nSorted Dataset (Merge Sort):\")\n",
    "sorted_df_merge = pd.DataFrame(sorted_data_merge)\n",
    "print(sorted_df_merge.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
